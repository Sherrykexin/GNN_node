best_valid_epoch:2.0
train loss:0.05191768
valid loss:0.0369862
test loss list:tf.Tensor(0.6456815, shape=(), dtype=float32)
mean test loss:0.6456815
mean loss list:tf.Tensor(0.0026809457, shape=(), dtype=float32)
mean mean loss:0.0026809457
accuracy list:[<tf.Tensor: shape=(), dtype=float64, numpy=0.9973118279569892>]
mean accuracy:0.9973118279569892
-------
/Users/sherry/Downloads/Systematic-Predicate-Abstraction-using-Machine-Learning-master/Heuristic_selection/benchmarks/single-layer-graph-example/test_data/jayhorn-tmp_0_000-581.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
predicted label:tf.Tensor(
[0.49538007 0.4712454  0.46598887 0.47358605 0.47261897 0.47729003
 0.475017   0.475017   0.475017   0.4701471  0.47313744 0.4729771
 0.4729771  0.4729771  0.4812427  0.47289824 0.48305133 0.475017
 0.48305133 0.475017   0.48305133 0.475017   0.48283738 0.4701471
 0.4895534  0.47313744 0.4839569  0.4729771  0.4839569  0.4729771
 0.4839569  0.4729771  0.47576153 0.47358605 0.47358605 0.4673537
 0.47534266 0.47261897 0.47261897 0.46999148 0.46911427 0.46911427
 0.46911427 0.46538395 0.46879902 0.46855652 0.46855652 0.46855652
 0.47184455 0.475017   0.475017   0.475017   0.4701471  0.47313744
 0.4729771  0.4729771  0.4729771  0.4812427  0.47184455 0.48305133
 0.475017   0.48305133 0.475017   0.48305133 0.475017   0.48283738
 0.4701471  0.4895534  0.47313744 0.4839569  0.4729771  0.4839569
 0.4729771  0.4839569  0.4729771  0.4757093  0.47576153 0.47325602
 0.47261897 0.47325602 0.47261897 0.47325602 0.47261897 0.4727428
 0.47534266 0.48224404 0.4673537  0.47555304 0.47358605 0.47555304
 0.47555304 0.47358605 0.4757093  0.46999148 0.47325602 0.46855652
 0.47325602 0.46855652 0.47325602 0.46855652 0.4727428  0.46879902
 0.48224404 0.46538395 0.47555304 0.46911427 0.47555304 0.46911427
 0.47555304 0.46911427 0.4755687  0.475017   0.475017   0.475017
 0.4701471  0.47313744 0.4729771  0.4729771  0.4729771  0.4812427
 0.47289824 0.48305133 0.475017   0.48305133 0.475017   0.48305133
 0.475017   0.48283738 0.4701471  0.4895534  0.47313744 0.4839569
 0.4729771  0.4839569  0.4729771  0.4839569  0.4729771  0.47723264
 0.4759405  0.4759405  0.4759405  0.4700214  0.47353628 0.4737116
 0.4737116  0.4737116  0.47122198 0.475017   0.475017   0.475017
 0.4701471  0.47313744 0.4729771  0.4729771  0.4729771  0.4812427
 0.47122198 0.48305133 0.475017   0.48305133 0.475017   0.48305133
 0.475017   0.48283738 0.4701471  0.4895534  0.47313744 0.4839569
 0.4729771  0.4839569  0.4729771  0.4839569  0.4729771  0.4757093
 0.47723264 0.47325602 0.4737116  0.47325602 0.4737116  0.47325602
 0.4737116  0.4727428  0.47353628 0.48224404 0.4700214  0.47555304
 0.4759405  0.47555304 0.4759405  0.47555304 0.4759405  0.4755687
 0.475017   0.475017   0.475017   0.4701471  0.47313744 0.4729771
 0.4729771  0.4729771  0.4812427  0.47289824 0.48305133 0.475017
 0.48305133 0.475017   0.48305133 0.475017   0.48283738 0.4701471
 0.4895534  0.47313744 0.4839569  0.4729771  0.4839569  0.4729771
 0.4839569  0.4729771  0.47451407 0.475017   0.475017   0.475017
 0.4701471  0.47313744 0.4729771  0.4729771  0.4729771  0.4812427
 0.47451407 0.48305133 0.475017   0.48305133 0.475017   0.48305133
 0.475017   0.48283738 0.4701471  0.4895534  0.47313744 0.4839569
 0.4729771  0.4839569  0.4729771  0.4839569  0.4729771  0.475017
 0.475017   0.4729771  0.4729771  0.48305133 0.475017   0.48305133
 0.475017   0.4839569  0.4729771  0.4839569  0.4729771  0.47358605
 0.47358605 0.47261897 0.47261897 0.46911427 0.46911427 0.46855652
 0.46855652 0.475017   0.475017   0.4729771  0.4729771  0.48305133
 0.475017   0.48305133 0.475017   0.4839569  0.4729771  0.4839569
 0.4729771  0.47325602 0.47261897 0.47325602 0.47261897 0.47555304
 0.47358605 0.47555304 0.47358605 0.47325602 0.46855652 0.47325602
 0.46855652 0.47555304 0.46911427 0.47555304 0.46911427 0.475017
 0.475017   0.4729771  0.4729771  0.48305133 0.475017   0.48305133
 0.475017   0.4839569  0.4729771  0.4839569  0.4729771  0.4759405
 0.4759405  0.4737116  0.4737116  0.475017   0.475017   0.4729771
 0.4729771  0.48305133 0.475017   0.48305133 0.475017   0.4839569
 0.4729771  0.4839569  0.4729771  0.47325602 0.4737116  0.47325602
 0.4737116  0.47555304 0.4759405  0.47555304 0.4759405  0.475017
 0.475017   0.4729771  0.4729771  0.48305133 0.475017   0.48305133
 0.475017   0.4839569  0.4729771  0.4839569  0.4729771  0.475017
 0.475017   0.4729771  0.4729771  0.48305133 0.475017   0.48305133
 0.475017   0.4839569  0.4729771  0.4839569  0.4729771  0.49215892
 0.4756275  0.46999148 0.47610542 0.46911427 0.47610542 0.46911427
 0.47610542 0.46911427 0.47347546 0.46538395 0.48626223 0.46879902
 0.48033473 0.46855652 0.48033473 0.46855652 0.48033473 0.46855652], shape=(372,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(372,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
mse:tf.Tensor(0.22628818, shape=(), dtype=float32)
-------
mean(mse_list):0.22628818
best_valid_epoch:1.0
train loss:0.08981047
valid loss:0.08711451
test loss list:tf.Tensor(0.64853525, shape=(), dtype=float32)
mean test loss:0.64853525
mean loss list:tf.Tensor(0.0161247, shape=(), dtype=float32)
mean mean loss:0.0161247
accuracy list:[<tf.Tensor: shape=(), dtype=float64, numpy=0.9836065573770492>]
mean accuracy:0.9836065573770492
-------
/Users/sherry/Downloads/Systematic-Predicate-Abstraction-using-Machine-Learning-master/Heuristic_selection/benchmarks/single-layer-graph-example/test_data/enc-zip4_000-772.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.48668647 0.48952588 0.48952588 0.4793159  0.4729246  0.46584553
 0.47636476 0.48043048 0.47137025 0.4729246  0.47359112 0.46584553
 0.4788987  0.47108904 0.4671057  0.4871464  0.4807055  0.47157705
 0.47942978 0.4729246  0.46584553 0.47636476 0.47942978 0.47137025
 0.4729246  0.47359112 0.46584553 0.4829383  0.4788987  0.47910532
 0.4671057  0.48535886 0.47108904 0.4829383  0.4871464  0.47910532
 0.47157705 0.48535886 0.4807055  0.48952588 0.48952588 0.4793159
 0.4729246  0.46584553 0.47636476 0.48043048 0.47137025 0.4729246
 0.47359112 0.46584553 0.4788987  0.47108904 0.4671057  0.4871464
 0.4807055  0.47157705 0.47942978 0.4729246  0.46584553 0.47636476
 0.47942978 0.47137025 0.4729246  0.47359112 0.46584553 0.4829383
 0.4788987  0.47910532 0.4671057  0.48535886 0.47108904 0.4829383
 0.4871464  0.47910532 0.47157705 0.48535886 0.4807055  0.49042258
 0.4729246  0.46584553 0.47636476 0.48043048 0.47137025 0.4729246
 0.47359112 0.46584553 0.48975798 0.4826957  0.4758235  0.48831394
 0.4729246  0.46584553 0.47636476 0.48831394 0.47137025 0.4729246
 0.47359112 0.46584553 0.4829383  0.48975798 0.47910532 0.4758235
 0.48535886 0.4826957  0.49042258 0.4729246  0.46584553 0.47636476
 0.48043048 0.47137025 0.4729246  0.47359112 0.46584553 0.48066857
 0.4729246  0.46584553 0.47636476 0.48066857 0.47137025 0.4729246
 0.47359112 0.4658455 ], shape=(122,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.], shape=(122,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.22771494, shape=(), dtype=float32)
-------
mean(mse_list):0.22771494
